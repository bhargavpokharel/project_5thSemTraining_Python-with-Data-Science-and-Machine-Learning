{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7605372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a0a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761ac73",
   "metadata": {},
   "source": [
    "Age        ‚Üí 714 non-null (missing ~177)\n",
    "Cabin      ‚Üí Only 204 non-null (too many missing ‚Üí drop)\n",
    "Embarked   ‚Üí 889 non-null (missing 2 rows)\n",
    "\n",
    "Task:\n",
    "\n",
    "Fill Age with median (numeric).\n",
    "\n",
    "Drop Cabin (too many nulls, not worth fixing).\n",
    "\n",
    "Fill Embarked with mode (most frequent port).\n",
    "\n",
    "Drop Ticket and Name (not useful for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f02fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ujen\\AppData\\Local\\Temp\\ipykernel_6612\\3375003939.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[\"Age\"].fillna(train_df[\"Age\"].median(), inplace=True)\n",
      "C:\\Users\\Ujen\\AppData\\Local\\Temp\\ipykernel_6612\\3375003939.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with too many missing values or not useful\n",
    "train_df = train_df.drop(columns=[\"Cabin\", \"Ticket\", \"Name\"])\n",
    "\n",
    "# Fill missing Age with median\n",
    "train_df[\"Age\"].fillna(train_df[\"Age\"].median(), inplace=True)\n",
    "\n",
    "# Fill missing Embarked with mode\n",
    "train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0], inplace=True)\n",
    "\n",
    "# Confirm no more missing values and show how many missing values exist in each column\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689b379",
   "metadata": {},
   "source": [
    "### Step 1: Encode Categorical Variables\n",
    "\n",
    "To prepare the data for machine learning models, we need to convert non-numeric (categorical) columns into numeric values:\n",
    "\n",
    "- Convert \"Sex\":\n",
    "  - male ‚Üí 0\n",
    "  - female ‚Üí 1\n",
    "\n",
    "- Convert \"Embarked\":\n",
    "  - S ‚Üí 0\n",
    "  - C ‚Üí 1\n",
    "  - Q ‚Üí 2\n",
    "\n",
    "These encodings allow models like Random Forest to interpret the data correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d64464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Sex\"] = train_df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].map({\"S\": 0, \"C\": 1, \"Q\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f1e59",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Features and Target\n",
    "\n",
    "We separate the dataset into:\n",
    "\n",
    "- **Features (X)**: The columns that the model will use to learn and predict (`Pclass`, `Sex`, `Age`, `SibSp`, `Parch`, `Fare`, `Embarked`)\n",
    "- **Target (y)**: The column to predict, which is `Survived` (0 = did not survive, 1 = survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077272fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Prepare Features and Target\n",
    "# Separate features (X) and target variable (y)\n",
    "X = train_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = train_df['Survived']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nFeatures used:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c70dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Data Splitting and Scaling\n",
    "# Split the training data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"\\nData scaled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model Selection and Training\n",
    "# Train Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Hyperparameter Tuning\n",
    "# Tune hyperparameters to improve accuracy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                          param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_accuracy = accuracy_score(y_val, best_model.predict(X_val_scaled))\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Predict on Test Data\n",
    "# Apply the selected model on the test dataset\n",
    "# First, clean and preprocess test data similar to training data\n",
    "\n",
    "# Clean test data\n",
    "test_df_clean = test_df.drop(columns=['Cabin', 'Ticket', 'Name'])\n",
    "\n",
    "# Fill missing values in test data\n",
    "test_df_clean['Age'].fillna(test_df_clean['Age'].median(), inplace=True)\n",
    "test_df_clean['Fare'].fillna(test_df_clean['Fare'].median(), inplace=True)\n",
    "test_df_clean['Embarked'].fillna(test_df_clean['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "test_df_clean['Sex'] = test_df_clean['Sex'].map({'male': 0, 'female': 1})\n",
    "test_df_clean['Embarked'] = test_df_clean['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "# Prepare test features\n",
    "X_test = test_df_clean[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "\n",
    "# Scale test features\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Test predictions completed!\")\n",
    "print(f\"Predicted survivors: {sum(test_predictions)}\")\n",
    "print(f\"Predicted non-survivors: {len(test_predictions) - sum(test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Save Predictions\n",
    "# Save predictions to CSV file\n",
    "submission.to_csv('titanic_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'titanic_predictions.csv'\")\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Visualization and Insights\n",
    "# Visualize feature importance and survival patterns\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Feature Importance\n",
    "axes[0, 0].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "axes[0, 0].set_title('Feature Importance')\n",
    "axes[0, 0].set_xlabel('Importance')\n",
    "\n",
    "# 2. Survival Rate by Gender\n",
    "survival_by_sex = train_df.groupby('Sex')['Survived'].mean()\n",
    "axes[0, 1].bar(['Male', 'Female'], survival_by_sex.values, color=['lightblue', 'lightcoral'])\n",
    "axes[0, 1].set_title('Survival Rate by Gender')\n",
    "axes[0, 1].set_ylabel('Survival Rate')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# 3. Survival Rate by Passenger Class\n",
    "survival_by_class = train_df.groupby('Pclass')['Survived'].mean()\n",
    "axes[1, 0].bar(survival_by_class.index, survival_by_class.values, color='skyblue')\n",
    "axes[1, 0].set_title('Survival Rate by Passenger Class')\n",
    "axes[1, 0].set_xlabel('Passenger Class')\n",
    "axes[1, 0].set_ylabel('Survival Rate')\n",
    "axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# 4. Age Distribution by Survival\n",
    "axes[1, 1].hist(train_df[train_df['Survived']==0]['Age'], alpha=0.7, label='Not Survived', bins=20)\n",
    "axes[1, 1].hist(train_df[train_df['Survived']==1]['Age'], alpha=0.7, label='Survived', bins=20)\n",
    "axes[1, 1].set_title('Age Distribution by Survival')\n",
    "axes[1, 1].set_xlabel('Age')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Summary and Key Insights\n",
    "# Summarize key insights from the data and model results\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TITANIC SURVIVAL PREDICTION - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Features used: {len(X.columns)}\")\n",
    "\n",
    "print(f\"\\nüéØ Model Performance:\")\n",
    "print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\nüîç Key Insights:\")\n",
    "print(f\"Overall survival rate: {train_df['Survived'].mean():.2%}\")\n",
    "\n",
    "# Gender insights\n",
    "female_survival = train_df[train_df['Sex']==1]['Survived'].mean()\n",
    "male_survival = train_df[train_df['Sex']==0]['Survived'].mean()\n",
    "print(f\"Female survival rate: {female_survival:.2%}\")\n",
    "print(f\"Male survival rate: {male_survival:.2%}\")\n",
    "\n",
    "# Class insights\n",
    "for pclass in sorted(train_df['Pclass'].unique()):\n",
    "    class_survival = train_df[train_df['Pclass']==pclass]['Survived'].mean()\n",
    "    print(f\"Class {pclass} survival rate: {class_survival:.2%}\")\n",
    "\n",
    "print(f\"\\nüèÜ Most Important Features:\")\n",
    "for i, (feature, importance) in enumerate(zip(feature_importance['feature'], feature_importance['importance']), 1):\n",
    "    print(f\"{i}. {feature}: {importance:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "print(\"- titanic_predictions.csv (predictions for test set)\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
